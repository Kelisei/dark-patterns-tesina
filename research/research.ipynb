{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56042f20729da0bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T15:45:16.636263700Z",
     "start_time": "2026-01-07T15:45:16.616386100Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from rich.jupyter import display\n",
    "\n",
    "ROOT = Path().resolve().parent\n",
    "sys.path.append(str(ROOT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8e85e76113fae40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T15:45:19.422162Z",
     "start_time": "2026-01-07T15:45:16.644263600Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0],\n",
       "       [ 0, 25]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from research.urgency import UrgencyPredictorNLP\n",
    "from research.scarcity import ScarcityPredictorNLP\n",
    "urgency_dataset = pd.read_csv(\"datasets/urgency.csv\")\n",
    "\n",
    "\n",
    "urgency_predictor  = UrgencyPredictorNLP()\n",
    "\n",
    "\n",
    "# Predict only giving the text column\n",
    "y_true = urgency_dataset[\"is_urgency\"]\n",
    "y_pred = urgency_predictor.predict_multiple(urgency_dataset[\"text\"])\n",
    "\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dec0cd2a18e5b7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T15:45:19.588671100Z",
     "start_time": "2026-01-07T15:45:19.460138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [2, 8]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scarcity_dataset = pd.read_csv(\"datasets/scarcity.csv\" )\n",
    "scarcity_predictor = ScarcityPredictorNLP()\n",
    "y_true = scarcity_dataset[\"is_scarcity\"]\n",
    "y_pred = scarcity_predictor.predict_multiple(scarcity_dataset[\"text\"])\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd014bcf10acc57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T15:45:19.739860100Z",
     "start_time": "2026-01-07T15:45:19.637251100Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Read from the datasets/images directory, get all the name of files, count scarcity and urgency based on if it's in the name\n",
    "\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "directory_path = \"datasets/images\"\n",
    "\n",
    "file_metrics = Counter({'scarcity': 0, 'urgency': 0, 'other': 0})\n",
    "\n",
    "if os.path.exists(directory_path):\n",
    "    files = [f.lower() for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "    for filename in files:\n",
    "        if \"scarcity\" in filename:\n",
    "            file_metrics['scarcity'] += 1\n",
    "        elif \"urgency\" in filename:\n",
    "            file_metrics['urgency'] += 1\n",
    "        else :\n",
    "            file_metrics['other'] += 1\n",
    "    print(f\"Total Files Scanned: {len(files)}\")\n",
    "    print(f\"Scarcity Count: {file_metrics['scarcity']}\")\n",
    "    print(f\"Urgency Count: {file_metrics['urgency']}\")\n",
    "    print(f\"Other Count: {file_metrics['other']}\")\n",
    "else:\n",
    "    print(f\"Error: The directory '{directory_path}' was not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c30069f08172c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T15:45:19.786831300Z",
     "start_time": "2026-01-07T15:45:19.766446300Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "counts = Counter()\n",
    "\n",
    "with open(\"datasets/unified_dataset.csv\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        counts[row[\"type\"]] += 1\n",
    "\n",
    "for k, v in counts.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e8cf1c0b6141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T15:45:20.499483900Z",
     "start_time": "2026-01-07T15:45:19.788334500Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# pip install wordcloud matplotlib\n",
    "\n",
    "import csv\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "STOPWORDS_ES = {\n",
    "    \"de\",\"la\",\"el\",\"y\",\"a\",\"en\",\"por\",\"para\",\"con\",\"sin\",\"un\",\"una\",\"unos\",\"unas\",\n",
    "    \"lo\",\"al\",\"del\",\"que\",\"se\",\"es\",\"este\",\"esta\",\"estos\",\"estas\",\"hay\",\"m√°s\",\"mas\",\n",
    "    \"ya\",\"ahora\",\"solo\",\"s√≥lo\",\"muy\",\"tu\",\"t√∫\",\"su\",\"sus\",\"mi\",\"mis\",\"te\",\"vos\",\"ustedes\",\n",
    "    \"desde\",\"hasta\",\"o\",\"u\",\"pero\",\"si\",\"s√≠\",\"me\",\"le\",\"les\",\"esto\",\"eso\",\"esa\",\"ese\",\n",
    "    \"min\",\"mins\",\"seg\",\"segs\",\"hs\",\"hora\",\"horas\",\"minutos\",\"segundos\",\"d√≠a\",\"dias\",\"d√≠as\"\n",
    "}\n",
    "\n",
    "def tokenize(text: str):\n",
    "    text = text.lower()\n",
    "    # normalizar n√∫meros/contadores para que no dominen la nube\n",
    "    text = re.sub(r\"\\d+([:.,]\\d+)*\", \" <NUM> \", text)  # 03:16:29:07, 11:58:14, 87%, etc\n",
    "    text = re.sub(r\"[^\\w√°√©√≠√≥√∫√±√º<>]+\", \" \", text, flags=re.UNICODE)\n",
    "    tokens = [t for t in text.split() if t not in STOPWORDS_ES and len(t) > 1]\n",
    "    return tokens\n",
    "\n",
    "# --- cargar CSV y construir texto ---\n",
    "tokens = []\n",
    "with open(\"datasets/unified_dataset.csv\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        tokens.extend(tokenize(row[\"content\"]))\n",
    "\n",
    "freq = Counter(tokens)\n",
    "\n",
    "# --- nube ---\n",
    "wc = WordCloud(\n",
    "    width=1400,\n",
    "    height=800,\n",
    "    background_color=\"white\",\n",
    "    collocations=False,  # evita juntar bigramas raros\n",
    "    max_words=200\n",
    ").generate_from_frequencies(freq)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.imshow(wc.to_image(), interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa4dab9d657f33d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T15:45:20.594676Z",
     "start_time": "2026-01-07T15:45:20.514975800Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CSV_PATH = \"datasets/unified_dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Limpieza m√≠nima\n",
    "df = df.dropna(subset=[\"type\", \"content\", \"source\"])\n",
    "df[\"type\"] = df[\"type\"].astype(str).str.strip()\n",
    "df[\"content\"] = df[\"content\"].astype(str).str.strip()\n",
    "df[\"source\"] = df[\"source\"].astype(str).str.strip()\n",
    "\n",
    "X = df[\"content\"]\n",
    "y = df[\"type\"]\n",
    "groups = df[\"source\"]\n",
    "\n",
    "# --- Eleg√≠ UNA de estas dos estrategias de split ---\n",
    "\n",
    "# (A) Split normal estratificado (m√°s f√°cil, pero puede ‚Äúmemorizar‚Äù estilo de sitios)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        ngram_range=(1, 2),      # unigramas + bigramas\n",
    "        min_df=2,                # ignora palabras ultra raras (ajustable)\n",
    "        max_df=0.95,             # ignora palabras demasiado comunes\n",
    "        strip_accents=None       # en espa√±ol prefiero no tocar acentos\n",
    "    )),\n",
    "    (\"clf\", LinearSVC())\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(\"=== Classification report ===\")\n",
    "print(classification_report(y_test, pred, digits=3))\n",
    "\n",
    "print(\"=== Confusion matrix ===\")\n",
    "labels = sorted(y.unique())\n",
    "cm = confusion_matrix(y_test, pred, labels=labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(values_format=\"d\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8811b77dcf1e512c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T15:45:20.689704400Z",
     "start_time": "2026-01-07T15:45:20.595675200Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report\n",
    "\n",
    "df = pd.read_csv(\"datasets/unified_dataset.csv\").dropna(subset=[\"type\", \"content\", \"source\"])\n",
    "df[\"type\"] = df[\"type\"].astype(str).str.strip()\n",
    "df[\"content\"] = df[\"content\"].astype(str).str.strip()\n",
    "df[\"source\"] = df[\"source\"].astype(str).str.strip()\n",
    "# df = df[df[\"type\"] != \"ninguno\"]\n",
    "\n",
    "X = df[\"content\"]\n",
    "y = df[\"type\"]\n",
    "groups = df[\"source\"]\n",
    "\n",
    "labels = sorted(y.unique())\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        ngram_range=(1, 3),\n",
    "        min_df=1,\n",
    "        max_df=0.95\n",
    "    )),\n",
    "    (\"clf\", LinearSVC(class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Predicciones out-of-fold (cada ejemplo se predice cuando su grupo est√° en test)\n",
    "oof_pred = np.empty(len(df), dtype=object)\n",
    "\n",
    "for train_idx, test_idx in gkf.split(X, y, groups):\n",
    "    pipeline.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "    oof_pred[test_idx] = pipeline.predict(X.iloc[test_idx])\n",
    "\n",
    "print(\"=== OOF Classification report (GroupKFold por source) ===\")\n",
    "print(classification_report(y, oof_pred, labels=labels, digits=3, zero_division=0))\n",
    "\n",
    "cm = confusion_matrix(y, oof_pred, labels=labels)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(values_format=\"d\")  # n√∫meros enteros\n",
    "plt.title(\"Matriz de confusi√≥n (OOF, GroupKFold por source)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6cd0d2991fb50fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T15:46:20.209673400Z",
     "start_time": "2026-01-07T15:46:20.145465900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STAGE 1: pattern vs ninguno ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     ninguno      0.688     0.716     0.702        74\n",
      "     pattern      0.806     0.784     0.795       111\n",
      "\n",
      "    accuracy                          0.757       185\n",
      "   macro avg      0.747     0.750     0.748       185\n",
      "weighted avg      0.759     0.757     0.758       185\n",
      "\n",
      "=== STAGE 2: urgency vs scarcity vs shaming ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "fake_scarcity      0.830     0.812     0.821        48\n",
      " fake_urgency      0.824     0.889     0.855        63\n",
      "      shaming      1.000     0.889     0.941        36\n",
      "\n",
      "     accuracy                          0.864       147\n",
      "    macro avg      0.884     0.863     0.872       147\n",
      " weighted avg      0.869     0.864     0.865       147\n",
      "\n",
      "Total errores Stage 1: 45\n",
      "\n",
      "=== FALSOS NEGATIVOS (pattern ‚Üí ninguno) ===\n",
      "- [47street] NO CUELGUES! EL SALE TERMINA EN 03:16:29:07 DIAS HS MIN SEG\n",
      "- [africamia_jeans] ¬°No te lo pierdas, es el √∫ltimo!\n",
      "- [banggod] Flash Deals 4D:12:24:50\n",
      "- [banggod] Fla‚ö°h Deals 4D:12:24:50\n",
      "- [bidcom] ¬°√öltimas unidades!\n",
      "- [bidcom] (6 disponibles)\n",
      "- [bozoom] Vendido hace 57 minutos\n",
      "- [domestika] Todos los cursos por 1239 ARS c/u 00 : 42 : 37 horas mins segs\n",
      "- [etsy] En m√°s de 20 carritos\n",
      "- [etsy] En 18 carritos\n",
      "- [loned&carla] ¬°No te lo pierdas, es el √∫ltimo!\n",
      "- [nord_vpn] Su estado: Desprotegido -69 % de descuento + 3 meses extra 00 : 09 : 37 : 34\n",
      "- [platzi] Aprovecha el precio especial El precio especial termina en: 1d 13h 38m 37s\n",
      "- [platzi] Aprovecha el precio especial Termina en: 1 d√≠as 13hrs 38min 11seg\n",
      "- [shein] Cup√≥n v√°lido en todo el sitio Expira en 23:59:53\n",
      "- [shein] -19% Venta Flash\n",
      "- [temu] QUEDA(N) 32\n",
      "- [temu] -43% ¬°ahora! ¬°Agrega al carrito!\n",
      "- [temu] -ARS9.714 adicional 11:58:14\n",
      "- [temu] -ARS5.446 adicional 11:58:14\n",
      "- [pazprofunda] ¬°Date prisa! Los paquetes promocionales se agotaran pronto\n",
      "- [stockcenter] ¬°√öltimas 4 unidades disponibles!\n",
      "- [temu] CASI AGOTADO(S)\n",
      "- [wish] ¬°Apurate! Estos descuentos terminan pronto\n",
      "\n",
      "=== FALSOS POSITIVOS (ninguno ‚Üí pattern) ===\n",
      "- [wish] Hasta 27% de descuento\n",
      "- [temu] ARS2.100 de cr√©dito por retraso\n",
      "- [temu] Llega a AR en tan solo 3 d√≠as h√°biles despu√©s del env√≠o\n",
      "- [Baeldung] Continuar sin apoyarnos\n",
      "- [eBook] Reject the ebook\n",
      "- [Desconocido] Soy una mala persona\n",
      "- [Desconocido] Descubrirlo ahora\n",
      "- [Delish] Mostrame 14 recetas simples\n",
      "- [Desconocido] Si, mandenm√© alertas de stock\n",
      "- [niacinamide] He le√≠do y acepto la pol√≠tica de privacidad\n",
      "- [IA] Clase de yoga termina en 10 minutos\n",
      "- [IA] La inscripci√≥n al curso cierra en 3 d√≠as\n",
      "- [IA] Su sesi√≥n expira en 5 minutos\n",
      "- [IA] El partido empieza en 15 minutos\n",
      "- [IA] La bater√≠a del dispositivo se agotar√° en 2h\n",
      "- [IA] recibe un regalo extra\n",
      "- [IA] Tu sesi√≥n caducar√° en 1 minuto\n",
      "- [IA] El examen comienza en 30 segundos\n",
      "- [IA] ¬°Participa ya!\n",
      "- [IA] gana descuentos exclusivos\n",
      "- [IA] √öltimas unidades disponibles\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "df = pd.read_csv(\"datasets/unified_dataset.csv\").dropna(subset=[\"type\",\"content\",\"source\"])\n",
    "\n",
    "df[\"binary\"] = df[\"type\"].apply(\n",
    "    lambda x: \"pattern\" if x in [\"fake_urgency\",\"fake_scarcity\"] else \"ninguno\"\n",
    ")\n",
    "\n",
    "X = df[\"content\"]\n",
    "y = df[\"binary\"]\n",
    "groups = df[\"source\"]\n",
    "\n",
    "pipeline_stage1 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,3), min_df=1, max_df=0.95)),\n",
    "    (\"clf\", LogisticRegression(max_iter=3000, class_weight={\"pattern\": 1.0, \"ninguno\": 2.0}))\n",
    "])\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "oof_pred = np.empty(len(df), dtype=object)\n",
    "\n",
    "for tr, te in gkf.split(X, y, groups):\n",
    "    pipeline_stage1.fit(X.iloc[tr], y.iloc[tr])\n",
    "    oof_pred[te] = pipeline_stage1.predict(X.iloc[te])\n",
    "\n",
    "print(\"=== STAGE 1: pattern vs ninguno ===\")\n",
    "print(classification_report(y, oof_pred, digits=3))\n",
    "\n",
    "\n",
    "df_p = df[df[\"type\"] != \"ninguno\"]\n",
    "\n",
    "X2 = df_p[\"content\"]\n",
    "y2 = df_p[\"type\"]\n",
    "groups2 = df_p[\"source\"]\n",
    "\n",
    "\n",
    "pipeline_stage2 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        ngram_range=(1,3),\n",
    "        min_df=1,\n",
    "        max_df=0.95\n",
    "    )),\n",
    "    (\"clf\", LinearSVC(class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "oof_pred2 = np.empty(len(df_p), dtype=object)\n",
    "\n",
    "for tr, te in gkf.split(X2, y2, groups2):\n",
    "    pipeline_stage2.fit(X2.iloc[tr], y2.iloc[tr])\n",
    "    oof_pred2[te] = pipeline_stage2.predict(X2.iloc[te])\n",
    "\n",
    "print(\"=== STAGE 2: urgency vs scarcity vs shaming ===\")\n",
    "print(classification_report(y2, oof_pred2, digits=3))\n",
    "\n",
    "# =========================\n",
    "# ERRORES STAGE 1\n",
    "# =========================\n",
    "df_stage1_err = df.copy()\n",
    "df_stage1_err[\"y_true\"] = y.values\n",
    "df_stage1_err[\"y_pred\"] = oof_pred\n",
    "\n",
    "# solo errores\n",
    "df_stage1_err = df_stage1_err[df_stage1_err[\"y_true\"] != df_stage1_err[\"y_pred\"]]\n",
    "\n",
    "print(f\"Total errores Stage 1: {len(df_stage1_err)}\")\n",
    "\n",
    "# Falsos negativos: pattern -> ninguno\n",
    "fn = df_stage1_err[\n",
    "    (df_stage1_err[\"y_true\"] == \"pattern\") &\n",
    "    (df_stage1_err[\"y_pred\"] == \"ninguno\")\n",
    "]\n",
    "\n",
    "print(\"\\n=== FALSOS NEGATIVOS (pattern ‚Üí ninguno) ===\")\n",
    "for _, r in fn.iterrows():\n",
    "    print(f\"- [{r['source']}] {r['content']}\")\n",
    "\n",
    "# Falsos positivos: ninguno -> pattern\n",
    "fp = df_stage1_err[\n",
    "    (df_stage1_err[\"y_true\"] == \"ninguno\") &\n",
    "    (df_stage1_err[\"y_pred\"] == \"pattern\")\n",
    "]\n",
    "\n",
    "print(\"\\n=== FALSOS POSITIVOS (ninguno ‚Üí pattern) ===\")\n",
    "for _, r in fp.iterrows():\n",
    "    print(f\"- [{r['source']}] {r['content']}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3c750de536440a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T15:45:20.798335100Z",
     "start_time": "2026-01-07T15:45:20.773242300Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline_stage1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     28\u001b[39m X_test = df_test[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# STAGE 1 ‚Äî pattern vs ninguno\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m y_pred_stage1 = \u001b[43mpipeline_stage1\u001b[49m.predict(X_test)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== EXTERNAL TEST ‚Äî STAGE 1 (pattern vs ninguno) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(classification_report(\n\u001b[32m     37\u001b[39m     y_true_stage1,\n\u001b[32m     38\u001b[39m     y_pred_stage1,\n\u001b[32m     39\u001b[39m     digits=\u001b[32m3\u001b[39m,\n\u001b[32m     40\u001b[39m     zero_division=\u001b[32m0\u001b[39m\n\u001b[32m     41\u001b[39m ))\n",
      "\u001b[31mNameError\u001b[39m: name 'pipeline_stage1' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- paths ---\n",
    "SCARCITY_PATH = \"datasets/scarcity.csv\"\n",
    "URGENCY_PATH  = \"datasets/urgency.csv\"\n",
    "\n",
    "# --- load ---\n",
    "df_sc = pd.read_csv(SCARCITY_PATH)   # is_scarcity, text, origin\n",
    "df_ur = pd.read_csv(URGENCY_PATH)    # is_urgency,  text, path\n",
    "\n",
    "# --- normalize schemas ---\n",
    "df_sc = df_sc.rename(columns={\"is_scarcity\":\"label\", \"origin\":\"meta\"})\n",
    "df_sc[\"task\"] = \"scarcity\"\n",
    "\n",
    "df_ur = df_ur.rename(columns={\"is_urgency\":\"label\", \"path\":\"meta\"})\n",
    "\n",
    "df_ur[\"task\"] = \"urgency\"\n",
    "\n",
    "df_test = pd.concat([df_sc[[\"label\",\"text\",\"task\",\"meta\"]],\n",
    "                     df_ur[[\"label\",\"text\",\"task\",\"meta\"]]], ignore_index=True)\n",
    "\n",
    "df_test[\"label\"] = df_test[\"label\"].astype(int)\n",
    "df_test[\"text\"]  = df_test[\"text\"].astype(str).str.strip()\n",
    "\n",
    "# ground truth binaria (pattern vs ninguno)\n",
    "y_true_stage1 = df_test[\"label\"].map({1: \"pattern\", 0: \"ninguno\"})\n",
    "X_test = df_test[\"text\"]\n",
    "\n",
    "# =========================\n",
    "# STAGE 1 ‚Äî pattern vs ninguno\n",
    "# =========================\n",
    "y_pred_stage1 = pipeline_stage1.predict(X_test)\n",
    "\n",
    "print(\"=== EXTERNAL TEST ‚Äî STAGE 1 (pattern vs ninguno) ===\")\n",
    "print(classification_report(\n",
    "    y_true_stage1,\n",
    "    y_pred_stage1,\n",
    "    digits=3,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# =========================\n",
    "# STAGE 2 ‚Äî urgency vs scarcity (solo patterns verdaderos que adem√°s pasaron stage1)\n",
    "# =========================\n",
    "mask = (df_test[\"label\"] == 1) & (y_pred_stage1 == \"pattern\")\n",
    "\n",
    "X_stage2 = df_test.loc[mask, \"text\"]\n",
    "y_true_stage2 = df_test.loc[mask, \"task\"].map({\"urgency\":\"fake_urgency\", \"scarcity\":\"fake_scarcity\"})\n",
    "\n",
    "if len(X_stage2) == 0:\n",
    "    print(\"\\n(No hay ejemplos que hayan pasado Stage 1 como 'pattern' para evaluar Stage 2.)\")\n",
    "else:\n",
    "    y_pred_stage2 = pipeline_stage2.predict(X_stage2)\n",
    "\n",
    "    print(\"\\n=== EXTERNAL TEST ‚Äî STAGE 2 (urgency vs scarcity) ===\")\n",
    "    print(classification_report(\n",
    "        y_true_stage2,\n",
    "        y_pred_stage2,\n",
    "        digits=3,\n",
    "        zero_division=0\n",
    "    ))\n",
    "\n",
    "    # opcional: ver cu√°les fall√≥\n",
    "    wrong = df_test.loc[mask].copy()\n",
    "    wrong[\"y_true\"] = y_true_stage2.values\n",
    "    wrong[\"y_pred\"] = y_pred_stage2\n",
    "    wrong = wrong[wrong[\"y_true\"] != wrong[\"y_pred\"]]\n",
    "    if len(wrong):\n",
    "        print(\"\\n--- Errores Stage 2 (muestra) ---\")\n",
    "        display(wrong[[\"task\",\"text\",\"meta\",\"y_true\",\"y_pred\"]].head(30))\n",
    "\n",
    "\n",
    "\n",
    "    # dataframe con resultados\n",
    "df_errors = df_test.copy()\n",
    "df_errors[\"y_true\"] = y_true_stage1.values\n",
    "df_errors[\"y_pred\"] = y_pred_stage1\n",
    "\n",
    "# solo errores\n",
    "df_errors = df_errors[df_errors[\"y_true\"] != df_errors[\"y_pred\"]]\n",
    "\n",
    "print(f\"Total errores Stage 1: {len(df_errors)}\")\n",
    "\n",
    "# -------------------------\n",
    "# Falsos negativos\n",
    "# pattern ‚Üí ninguno\n",
    "# -------------------------\n",
    "fn = df_errors[(df_errors[\"y_true\"] == \"pattern\") & (df_errors[\"y_pred\"] == \"ninguno\")]\n",
    "\n",
    "print(\"\\n=== FALSOS NEGATIVOS (pattern ‚Üí ninguno) ===\")\n",
    "for _, r in fn.iterrows():\n",
    "    print(f\"- TEXT: {r['text']}\")\n",
    "\n",
    "# -------------------------\n",
    "# Falsos positivos\n",
    "# ninguno ‚Üí pattern\n",
    "# -------------------------\n",
    "fp = df_errors[(df_errors[\"y_true\"] == \"ninguno\") & (df_errors[\"y_pred\"] == \"pattern\")]\n",
    "\n",
    "print(\"\\n=== FALSOS POSITIVOS (ninguno ‚Üí pattern) ===\")\n",
    "for _, r in fp.iterrows():\n",
    "    print(f\"- TEXT: {r['text']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9774e885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ScarcityPredictorNLP (fake_scarcity vs resto) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.801     0.942     0.866       137\n",
      "           1      0.667     0.333     0.444        48\n",
      "\n",
      "    accuracy                          0.784       185\n",
      "   macro avg      0.734     0.637     0.655       185\n",
      "weighted avg      0.766     0.784     0.756       185\n",
      "\n",
      "Errores totales: 40 | FP: 8 | FN: 32\n",
      "\n",
      "-- FALSOS POSITIVOS (predijo True pero era otra clase) [hasta 25] --\n",
      "- TRUE=fake_urgency | [shein] -28% | √öltimo d√≠a\n",
      "- TRUE=fake_urgency | [shein] ¬°√öltimo d√≠a\n",
      "- TRUE=fake_urgency | [temu] -29% √∫ltimos 2 d√≠as\n",
      "- TRUE=fake_urgency | [temu] √öltimo d√≠a\n",
      "- TRUE=fake_urgency | [spotify] √öltima oportunidad\n",
      "- TRUE=fake_urgency | [temu] Solo quedan 12 horas para obtener 21% de descuento\n",
      "- TRUE=ninguno | [wish] 4 colores, 5 piezas\n",
      "- TRUE=ninguno | [IA] √öltimas unidades disponibles\n",
      "\n",
      "-- FALSOS NEGATIVOS (no detect√≥, pero era la clase objetivo) [hasta 25] --\n",
      "- TRUE=fake_scarcity | [africamia_jeans] ¬°No te lo pierdas, es el √∫ltimo!\n",
      "- TRUE=fake_scarcity | [alevmayorista] 7 ¬°Personas estan viendo este producto ahora!\n",
      "- TRUE=fake_scarcity | [amazon] Solo queda(n) 1 en stock (hay m√°s unidades en camino).\n",
      "- TRUE=fake_scarcity | [bbriw_cosmetics] 15 personas est√°n viendo esto ahora mismo\n",
      "- TRUE=fake_scarcity | [bidcom] (6 disponibles)\n",
      "- TRUE=fake_scarcity | [boca] ¬°√öltimos! (1 disponibles)\n",
      "- TRUE=fake_scarcity | [boca] Stock disponible: (19 disponibles)\n",
      "- TRUE=fake_scarcity | [bozoom] ¬°Quedan solo 2 en stock!\n",
      "- TRUE=fake_scarcity | [bozoom] Vendido hace 57 minutos\n",
      "- TRUE=fake_scarcity | [coderhouse] Quedan 3 lugares üî•\n",
      "- TRUE=fake_scarcity | [coderhouse] Quedan 6 lugares üî•\n",
      "- TRUE=fake_scarcity | [coderhouse] Quedan 7 lugares üî•\n",
      "- TRUE=fake_scarcity | [comprasentacna] üî• 34 personas est√°n viendo este producto.\n",
      "- TRUE=fake_scarcity | [comprasentacna] üî• 45 personas est√°n viendo este producto.\n",
      "- TRUE=fake_scarcity | [comprasentacna] üî• 42 personas est√°n viendo este producto.\n",
      "- TRUE=fake_scarcity | [comprasentacna] üî• 43 personas est√°n viendo este producto.\n",
      "- TRUE=fake_scarcity | [crehana] ¬°Hay 6 personas que est√°n comprando lo mismo que t√∫ desde colombia!\n",
      "- TRUE=fake_scarcity | [discordiapersa] ¬°No te lo pierdas, es el √∫ltimo!\n",
      "- TRUE=fake_scarcity | [ebay] √öltimo\n",
      "- TRUE=fake_scarcity | [etsy] En m√°s de 20 carritos\n",
      "- TRUE=fake_scarcity | [etsy] En 18 carritos\n",
      "- TRUE=fake_scarcity | [etsy] Solo hay 1 y est√° en 1 carrito\n",
      "- TRUE=fake_scarcity | [glowetta] PRODUCTO VIRAL | STOCK BAJO\n",
      "- TRUE=fake_scarcity | [glowetta] Juan P. acaba de comprar Aceite de or√©gano PACK 2 hace 5 minutos\n",
      "- TRUE=fake_scarcity | [hospedium] ¬°Quedan 2 habitaciones disponibles!\n",
      "\n",
      "=== UrgencyPredictorNLP (fake_urgency vs resto) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.783     0.975     0.869       122\n",
      "           1      0.909     0.476     0.625        63\n",
      "\n",
      "    accuracy                          0.805       185\n",
      "   macro avg      0.846     0.726     0.747       185\n",
      "weighted avg      0.826     0.805     0.786       185\n",
      "\n",
      "Errores totales: 36 | FP: 3 | FN: 33\n",
      "\n",
      "-- FALSOS POSITIVOS (predijo True pero era otra clase) [hasta 25] --\n",
      "- TRUE=fake_scarcity | [etsy] Quedan 2 unidades y una est√° en el carrito de otra persona\n",
      "- TRUE=fake_scarcity | [pazprofunda] Actualizaci√≥n: Solo quedan 37 unidades a partir de.\n",
      "- TRUE=ninguno | [wish] Hasta 27% de descuento\n",
      "\n",
      "-- FALSOS NEGATIVOS (no detect√≥, pero era la clase objetivo) [hasta 25] --\n",
      "- TRUE=fake_urgency | [47street] NO CUELGUES! EL SALE TERMINA EN 03:16:29:07 DIAS HS MIN SEG\n",
      "- TRUE=fake_urgency | [47street] NO CUELGUES! EL SALE TERMINA EN 00:7:35:52 DIAS HS MIN SEG\n",
      "- TRUE=fake_urgency | [aliexpress] La Promo Termina: 8 ene., 04:59 (GMT-3) OFERTAS DE A√ëO NUEVO\n",
      "- TRUE=fake_urgency | [aliexpress] SuperOfertas Acaba en: 16:57:01\n",
      "- TRUE=fake_urgency | [aliexpress] Ofertas de A√±o Nuevo ¬∑ SuperOfertas Termina: 8 ene., 04:59 (GMT-3)\n",
      "- TRUE=fake_urgency | [banggod] Fla‚ö°h Deals 4D:12:24:50\n",
      "- TRUE=fake_urgency | [bidcom] OFERTAS PICANTES HASTA 30% OFF FINALIZA EN 00 : 28 : 00 Horas ¬∑ Minutos ¬∑ Segundos\n",
      "- TRUE=fake_urgency | [bidcom] picante FINALIZA EN 00 : 09 : 38 Horas  Minutos  Segundos Ver Productos\n",
      "- TRUE=fake_urgency | [bidcom] OFERTA BOMBA FINALIZA EN: 02:08:56\n",
      "- TRUE=fake_urgency | [coderhouse] CODER SALE üí• Hasta el 07/01\n",
      "- TRUE=fake_urgency | [coderhouse] CODER SALE üí• Finaliza en: 2d 12h 48m 51s\n",
      "- TRUE=fake_urgency | [domestika] Todos los cursos por 1239 ARS c/u 00 : 42 : 37 horas mins segs\n",
      "- TRUE=fake_urgency | [falabella] SOLO x 24h 00 : 54 : 38\n",
      "- TRUE=fake_urgency | [falabella] SOLO x 24h 18 : 21 : 52\n",
      "- TRUE=fake_urgency | [fravega] V√°lido del 26/12 al 6/01\n",
      "- TRUE=fake_urgency | [gadnic] ¬°NO TE LAS PIERDAS! QUEDAN: 00 : 36 : 29 Horas Mins Seg\n",
      "- TRUE=fake_urgency | [gadnic] OFERTA BOMBA Finaliza en: 02:26:03\n",
      "- TRUE=fake_urgency | [gadnic] OFERTA BOMBA Finaliza en: 00:26:03\n",
      "- TRUE=fake_urgency | [gadnic] OFERTA BOMBA Finaliza en: 04:26:03\n",
      "- TRUE=fake_urgency | [hostinger] Hasta 72% off 02 : 19 : 39 : 53\n",
      "- TRUE=fake_urgency | [mercado_libre] ¬°NO TE LO PIERDAS! QUEDAN 00 : 14 : 58 : 13 DE DESCUENTOS 9/9\n",
      "- TRUE=fake_urgency | [nord_vpn] Su estado: Desprotegido -69 % de descuento + 3 meses extra 00 : 09 : 37 : 34\n",
      "- TRUE=fake_urgency | [rappi] ¬°Ten√©s 30 d√≠as de entregas gratis!\n",
      "- TRUE=fake_urgency | [temu] -29% √∫ltimos 2 d√≠as\n",
      "- TRUE=fake_urgency | [temu] -43% ¬°ahora! ¬°Agrega al carrito!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from research.urgency import UrgencyPredictorNLP\n",
    "from research.scarcity import ScarcityPredictorNLP\n",
    "\n",
    "df = pd.read_csv(\"datasets/unified_dataset.csv\").dropna(subset=[\"type\",\"content\",\"source\"])\n",
    "df[\"type\"] = df[\"type\"].astype(str).str.strip()\n",
    "df[\"content\"] = df[\"content\"].astype(str).str.strip()\n",
    "df[\"source\"] = df[\"source\"].astype(str).str.strip()\n",
    "\n",
    "scar_model = ScarcityPredictorNLP()\n",
    "urg_model  = UrgencyPredictorNLP()\n",
    "\n",
    "def eval_with_strategy(df, target_type: str, strategy, title: str):\n",
    "    y_true = (df[\"type\"] == target_type).astype(int).to_numpy()\n",
    "\n",
    "    # usa la clase (predict_multiple)\n",
    "    preds_bool = strategy.predict_multiple(df[\"content\"])\n",
    "    y_pred = pd.Series(preds_bool).astype(int).to_numpy()\n",
    "\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(classification_report(y_true, y_pred, digits=3, zero_division=0))\n",
    "\n",
    "    # errores (FP/FN)\n",
    "    tmp = df.copy()\n",
    "    tmp[\"y_true\"] = y_true\n",
    "    tmp[\"y_pred\"] = y_pred\n",
    "    err = tmp[tmp[\"y_true\"] != tmp[\"y_pred\"]]\n",
    "\n",
    "    fp = err[(err[\"y_true\"] == 0) & (err[\"y_pred\"] == 1)]\n",
    "    fn = err[(err[\"y_true\"] == 1) & (err[\"y_pred\"] == 0)]\n",
    "\n",
    "    print(f\"Errores totales: {len(err)} | FP: {len(fp)} | FN: {len(fn)}\")\n",
    "\n",
    "    print(\"\\n-- FALSOS POSITIVOS (predijo True pero era otra clase) [hasta 25] --\")\n",
    "    for _, r in fp.head(25).iterrows():\n",
    "        print(f\"- TRUE={r['type']} | [{r['source']}] {r['content']}\")\n",
    "\n",
    "    print(\"\\n-- FALSOS NEGATIVOS (no detect√≥, pero era la clase objetivo) [hasta 25] --\")\n",
    "    for _, r in fn.head(25).iterrows():\n",
    "        print(f\"- TRUE={r['type']} | [{r['source']}] {r['content']}\")\n",
    "\n",
    "# Scarcity vs resto\n",
    "eval_with_strategy(\n",
    "    df=df,\n",
    "    target_type=\"fake_scarcity\",\n",
    "    strategy=scar_model,\n",
    "    title=\"ScarcityPredictorNLP (fake_scarcity vs resto)\"\n",
    ")\n",
    "\n",
    "# Urgency vs resto\n",
    "eval_with_strategy(\n",
    "    df=df,\n",
    "    target_type=\"fake_urgency\",\n",
    "    strategy=urg_model,\n",
    "    title=\"UrgencyPredictorNLP (fake_urgency vs resto)\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
